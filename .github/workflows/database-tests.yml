name: Database Testing Framework - Complete Suite

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'sql/**'
      - 'src/**'
      - '.github/workflows/database-tests.yml'
      - 'docs/testing/**'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'sql/**'
      - 'src/**'
      - '.github/workflows/database-tests.yml'

  # Scheduled runs for monitoring
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM UTC
    - cron: '0 */6 * * *'  # Every 6 hours for continuous monitoring

  # Manual trigger for emergency testing
  workflow_dispatch:
    inputs:
      test_categories:
        description: 'Test categories to run (comma-separated: unit,integration,security,performance,migration,stress,regression,edge,recovery,monitoring)'
        required: false
        default: 'all'
      skip_performance_tests:
        description: 'Skip performance tests for faster execution'
        required: false
        default: false
        type: boolean
      production_safe_mode:
        description: 'Run in production-safe mode with limited operations'
        required: false
        default: false
        type: boolean

env:
  NODE_VERSION: '18'
  POSTGRES_VERSION: '15'
  PGTAP_VERSION: 'v1.2.0'
  
  # Test execution settings
  TEST_TIMEOUT_MINUTES: 30
  PARALLEL_JOBS: 4
  PERFORMANCE_REGRESSION_THRESHOLD: 20
  
  # Quality gate thresholds
  MIN_SUCCESS_RATE: 97
  MAX_EXECUTION_TIME_MINUTES: 5

jobs:
  # Phase 1: Infrastructure Setup and Validation
  setup-and-validate:
    name: Infrastructure Setup & Validation
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    outputs:
      test-categories: ${{ steps.determine-tests.outputs.categories }}
      database-url: ${{ steps.setup-db.outputs.database-url }}
      baseline-exists: ${{ steps.check-baseline.outputs.exists }}
      
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_supabase_crm
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Cache pgTAP Installation
        id: cache-pgtap
        uses: actions/cache@v3
        with:
          path: |
            /usr/share/postgresql/*/extension/pgtap*
            /usr/lib/postgresql/*/lib/pgtap.so
          key: ${{ runner.os }}-pgtap-${{ env.PGTAP_VERSION }}
          
      - name: Install pgTAP Dependencies
        if: steps.cache-pgtap.outputs.cache-hit != 'true'
        run: |
          echo "🔧 Installing pgTAP and dependencies..."
          sudo apt-get update -qq
          sudo apt-get install -yqq postgresql-contrib pgtap
          
          # Install Perl TAP modules
          sudo cpan -T TAP::Parser::SourceHandler::pgTAP
          
      - name: Verify pgTAP Installation
        run: |
          echo "✅ Verifying pgTAP installation..."
          pg_prove --version
          psql --version
          
      - name: Setup Database Schema
        id: setup-db
        env:
          PGPASSWORD: postgres
        run: |
          echo "🏗️ Setting up database schema..."
          
          # Apply all database schema files in order
          find sql -name "*.sql" -not -path "*/tests/*" -not -name "*test*" | sort | while read -r file; do
            echo "Applying: $file"
            if ! psql -h localhost -U postgres -d test_supabase_crm -f "$file"; then
              echo "❌ Failed to apply: $file"
              exit 1
            fi
          done
          
          # Set output for downstream jobs
          echo "database-url=postgresql://postgres:postgres@localhost:5432/test_supabase_crm" >> $GITHUB_OUTPUT
          
      - name: Install Test Framework
        env:
          SUPABASE_DB_URL: postgresql://postgres:postgres@localhost:5432/test_supabase_crm
        run: |
          echo "⚙️ Installing database testing framework..."
          chmod +x sql/tests/run_tests.sh
          
          # Setup test framework infrastructure
          if ! ./sql/tests/run_tests.sh --setup-only; then
            echo "❌ Test framework setup failed"
            exit 1
          fi
          
          echo "✅ Test framework installed successfully"
          
      - name: Determine Test Categories
        id: determine-tests
        run: |
          if [ "${{ github.event.inputs.test_categories }}" = "all" ] || [ -z "${{ github.event.inputs.test_categories }}" ]; then
            categories="unit,integration,security,performance,migration,stress,regression,edge,recovery,monitoring"
          else
            categories="${{ github.event.inputs.test_categories }}"
          fi
          
          # Remove performance if skipped
          if [ "${{ github.event.inputs.skip_performance_tests }}" = "true" ]; then
            categories=$(echo $categories | sed 's/,performance//g' | sed 's/performance,//g')
          fi
          
          echo "categories=$categories" >> $GITHUB_OUTPUT
          echo "🎯 Test categories to execute: $categories"
          
      - name: Check Performance Baselines
        id: check-baseline
        env:
          SUPABASE_DB_URL: postgresql://postgres:postgres@localhost:5432/test_supabase_crm
        run: |
          # Check if performance baselines exist
          if psql "$SUPABASE_DB_URL" -c "SELECT 1 FROM test_schema.performance_baselines LIMIT 1;" >/dev/null 2>&1; then
            echo "exists=true" >> $GITHUB_OUTPUT
            echo "✅ Performance baselines found"
          else
            echo "exists=false" >> $GITHUB_OUTPUT
            echo "ℹ️ No performance baselines found - will establish new baselines"
          fi
          
      - name: Infrastructure Health Check
        env:
          SUPABASE_DB_URL: postgresql://postgres:postgres@localhost:5432/test_supabase_crm
        run: |
          echo "🔍 Performing infrastructure health check..."
          
          # Check database connectivity
          psql "$SUPABASE_DB_URL" -c "SELECT 'Database connection: OK';"
          
          # Check pgTAP availability
          psql "$SUPABASE_DB_URL" -c "SELECT 'pgTAP extension: ' || CASE WHEN EXISTS(SELECT 1 FROM pg_extension WHERE extname = 'pgtap') THEN 'OK' ELSE 'MISSING' END;"
          
          # Check test schema setup
          psql "$SUPABASE_DB_URL" -c "SELECT 'Test schema: ' || CASE WHEN EXISTS(SELECT 1 FROM information_schema.schemata WHERE schema_name = 'test_schema') THEN 'OK' ELSE 'MISSING' END;"
          
          echo "✅ Infrastructure health check completed"

  # Phase 2: Unit Tests - Fast feedback loop
  unit-tests:
    name: Unit Tests (25+ tests)
    runs-on: ubuntu-latest
    needs: setup-and-validate
    timeout-minutes: 15
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_supabase_crm
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Restore pgTAP Cache
        uses: actions/cache@v3
        with:
          path: |
            /usr/share/postgresql/*/extension/pgtap*
            /usr/lib/postgresql/*/lib/pgtap.so
          key: ${{ runner.os }}-pgtap-${{ env.PGTAP_VERSION }}
          
      - name: Install Dependencies
        run: |
          sudo apt-get update -qq
          sudo apt-get install -yqq postgresql-contrib pgtap
          sudo cpan -T TAP::Parser::SourceHandler::pgTAP
          
      - name: Setup Database and Test Framework
        env:
          PGPASSWORD: postgres
          SUPABASE_DB_URL: postgresql://postgres:postgres@localhost:5432/test_supabase_crm
        run: |
          # Apply schema
          find sql -name "*.sql" -not -path "*/tests/*" -not -name "*test*" | sort | while read -r file; do
            psql -h localhost -U postgres -d test_supabase_crm -f "$file" >/dev/null
          done
          
          # Setup test framework
          chmod +x sql/tests/run_tests.sh
          ./sql/tests/run_tests.sh --setup-only
          
      - name: Execute Unit Tests
        env:
          SUPABASE_DB_URL: postgresql://postgres:postgres@localhost:5432/test_supabase_crm
        run: |
          echo "🧪 Executing unit tests..."
          
          # Run unit tests with detailed output
          if ./sql/tests/run_tests.sh --unit-only --verbose --parallel; then
            echo "✅ Unit tests completed successfully"
          else
            echo "❌ Unit tests failed"
            exit 1
          fi
          
      - name: Collect Unit Test Results
        if: always()
        run: |
          # Create results directory
          mkdir -p test-results/unit
          
          # Collect test output and metrics
          if [ -f sql/tests/results/unit_test_results.json ]; then
            cp sql/tests/results/unit_test_results.json test-results/unit/
          fi
          
          # Generate unit test summary
          echo "## Unit Test Results" > test-results/unit/summary.md
          echo "- Test Category: Unit Tests" >> test-results/unit/summary.md
          echo "- Execution Time: $(date)" >> test-results/unit/summary.md
          echo "- Status: $([ $? -eq 0 ] && echo 'PASSED' || echo 'FAILED')" >> test-results/unit/summary.md
          
      - name: Upload Unit Test Artifacts
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: unit-test-results
          path: test-results/unit/
          retention-days: 30

  # Phase 3: Security Tests - Critical for production
  security-tests:
    name: Security Tests (217+ tests)
    runs-on: ubuntu-latest
    needs: [setup-and-validate, unit-tests]
    timeout-minutes: 20
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_supabase_crm
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Test Environment
        env:
          PGPASSWORD: postgres
          SUPABASE_DB_URL: postgresql://postgres:postgres@localhost:5432/test_supabase_crm
        run: |
          # Install dependencies
          sudo apt-get update -qq
          sudo apt-get install -yqq postgresql-contrib pgtap
          sudo cpan -T TAP::Parser::SourceHandler::pgTAP
          
          # Setup database and test framework
          find sql -name "*.sql" -not -path "*/tests/*" -not -name "*test*" | sort | while read -r file; do
            psql -h localhost -U postgres -d test_supabase_crm -f "$file" >/dev/null
          done
          
          chmod +x sql/tests/run_tests.sh
          ./sql/tests/run_tests.sh --setup-only
          
      - name: Execute Security Tests
        env:
          SUPABASE_DB_URL: postgresql://postgres:postgres@localhost:5432/test_supabase_crm
        run: |
          echo "🔒 Executing security tests..."
          
          # Run security tests with comprehensive validation
          if ./sql/tests/run_tests.sh --security --verbose; then
            echo "✅ Security tests completed successfully"
          else
            echo "❌ Security tests failed"
            exit 1
          fi
          
      - name: Validate RLS Performance Impact
        env:
          SUPABASE_DB_URL: postgresql://postgres:postgres@localhost:5432/test_supabase_crm
        run: |
          echo "⚡ Validating RLS performance impact..."
          
          # Run RLS performance validation (should be <15% overhead)
          ./sql/tests/scripts/validate_rls_performance.sh
          
      - name: Security Compliance Check
        env:
          SUPABASE_DB_URL: postgresql://postgres:postgres@localhost:5432/test_supabase_crm
        run: |
          echo "📋 Running security compliance checks..."
          
          # Check GDPR compliance
          psql "$SUPABASE_DB_URL" -c "
            DO \$\$
            DECLARE
                rls_tables INTEGER;
                total_tables INTEGER;
                coverage_percent DECIMAL;
            BEGIN
                SELECT COUNT(*) INTO total_tables
                FROM information_schema.tables
                WHERE table_schema = 'public' AND table_type = 'BASE TABLE';
                
                SELECT COUNT(*) INTO rls_tables
                FROM pg_class c
                JOIN pg_namespace n ON c.relnamespace = n.oid
                WHERE n.nspname = 'public' AND c.relkind = 'r' AND c.relrowsecurity = true;
                
                coverage_percent := (rls_tables::DECIMAL / total_tables) * 100;
                
                RAISE NOTICE '🔒 RLS Coverage: %% (% out of % tables)', 
                            ROUND(coverage_percent, 1), rls_tables, total_tables;
                
                IF coverage_percent < 80 THEN
                    RAISE EXCEPTION 'Insufficient RLS coverage: %%. Minimum 80%% required.', coverage_percent;
                END IF;
            END
            \$\$;
          "
          
      - name: Upload Security Test Results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: security-test-results
          path: sql/tests/results/
          retention-days: 30

  # Phase 4: Performance Tests - Scalability validation
  performance-tests:
    name: Performance Tests (188+ tests)
    runs-on: ubuntu-latest
    needs: [setup-and-validate, unit-tests]
    if: ${{ !inputs.skip_performance_tests }}
    timeout-minutes: 25
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_supabase_crm
          POSTGRES_SHARED_PRELOAD_LIBRARIES: pg_stat_statements
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Performance Test Environment
        env:
          PGPASSWORD: postgres
          SUPABASE_DB_URL: postgresql://postgres:postgres@localhost:5432/test_supabase_crm
        run: |
          # Install dependencies
          sudo apt-get update -qq
          sudo apt-get install -yqq postgresql-contrib pgtap
          sudo cpan -T TAP::Parser::SourceHandler::pgTAP
          
          # Setup database with performance extensions
          find sql -name "*.sql" -not -path "*/tests/*" -not -name "*test*" | sort | while read -r file; do
            psql -h localhost -U postgres -d test_supabase_crm -f "$file" >/dev/null
          done
          
          # Enable performance monitoring
          psql -h localhost -U postgres -d test_supabase_crm -c "
            CREATE EXTENSION IF NOT EXISTS pg_stat_statements;
            SELECT pg_stat_statements_reset();
          "
          
          # Setup test framework
          chmod +x sql/tests/run_tests.sh
          ./sql/tests/run_tests.sh --setup-only
          
      - name: Load Performance Test Data
        env:
          SUPABASE_DB_URL: postgresql://postgres:postgres@localhost:5432/test_supabase_crm
        run: |
          echo "📊 Loading performance test dataset..."
          
          # Load substantial test data for performance testing
          psql "$SUPABASE_DB_URL" -c "
            SELECT test_schema.load_performance_test_data(
              10000,  -- contacts
              2000,   -- organizations  
              5000,   -- opportunities
              15000   -- interactions
            );
          "
          
      - name: Execute Performance Tests
        env:
          SUPABASE_DB_URL: postgresql://postgres:postgres@localhost:5432/test_supabase_crm
        run: |
          echo "⚡ Executing performance tests..."
          
          # Run performance tests with detailed metrics collection
          if ./sql/tests/run_tests.sh --performance --verbose --parallel; then
            echo "✅ Performance tests completed successfully"
          else
            echo "❌ Performance tests failed"
            exit 1
          fi
          
      - name: Performance Regression Analysis
        env:
          SUPABASE_DB_URL: postgresql://postgres:postgres@localhost:5432/test_supabase_crm
          BASELINE_EXISTS: ${{ needs.setup-and-validate.outputs.baseline-exists }}
        run: |
          echo "📈 Analyzing performance regression..."
          
          if [ "$BASELINE_EXISTS" = "true" ]; then
            # Run regression analysis against existing baselines
            ./sql/tests/scripts/performance_regression_analysis.sh
          else
            echo "ℹ️ No baseline found - establishing new performance baselines"
            ./sql/tests/scripts/establish_performance_baselines.sh
          fi
          
      - name: Generate Performance Report
        env:
          SUPABASE_DB_URL: postgresql://postgres:postgres@localhost:5432/test_supabase_crm
        run: |
          echo "📋 Generating performance report..."
          
          # Export performance metrics
          psql "$SUPABASE_DB_URL" -c "
            COPY (
              SELECT json_agg(
                json_build_object(
                  'query', query,
                  'calls', calls,
                  'mean_exec_time', round(mean_exec_time::numeric, 2),
                  'total_exec_time', round(total_exec_time::numeric, 2),
                  'rows', rows,
                  'hit_ratio', round((blk_read_time / (blk_read_time + blk_write_time) * 100)::numeric, 2)
                )
              )
              FROM pg_stat_statements
              WHERE calls > 5
              ORDER BY mean_exec_time DESC
            ) TO '/tmp/performance_metrics.json';
          "
          
          # Copy to artifacts
          sudo cp /tmp/performance_metrics.json sql/tests/results/
          
      - name: Upload Performance Test Results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: performance-test-results
          path: sql/tests/results/
          retention-days: 30

  # Phase 5: Integration Tests - Business logic validation
  integration-tests:
    name: Integration Tests (229+ tests)
    runs-on: ubuntu-latest
    needs: [setup-and-validate, unit-tests, security-tests]
    timeout-minutes: 30
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_supabase_crm
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Integration Test Environment
        env:
          PGPASSWORD: postgres
          SUPABASE_DB_URL: postgresql://postgres:postgres@localhost:5432/test_supabase_crm
        run: |
          # Install dependencies
          sudo apt-get update -qq
          sudo apt-get install -yqq postgresql-contrib pgtap
          sudo cpan -T TAP::Parser::SourceHandler::pgTAP
          
          # Setup database and test framework
          find sql -name "*.sql" -not -path "*/tests/*" -not -name "*test*" | sort | while read -r file; do
            psql -h localhost -U postgres -d test_supabase_crm -f "$file" >/dev/null
          done
          
          chmod +x sql/tests/run_tests.sh
          ./sql/tests/run_tests.sh --setup-only
          
      - name: Execute Integration Tests
        env:
          SUPABASE_DB_URL: postgresql://postgres:postgres@localhost:5432/test_supabase_crm
        run: |
          echo "🔗 Executing integration tests..."
          
          # Run integration tests with comprehensive workflow validation
          if ./sql/tests/run_tests.sh --integration --verbose; then
            echo "✅ Integration tests completed successfully"
          else
            echo "❌ Integration tests failed"
            exit 1
          fi
          
      - name: Business Logic Validation
        env:
          SUPABASE_DB_URL: postgresql://postgres:postgres@localhost:5432/test_supabase_crm
        run: |
          echo "💼 Validating business logic workflows..."
          
          # Run comprehensive CRM workflow tests
          ./sql/tests/run_tests.sh --business-logic --comprehensive
          
      - name: Data Consistency Verification
        env:
          SUPABASE_DB_URL: postgresql://postgres:postgres@localhost:5432/test_supabase_crm
        run: |
          echo "🔍 Verifying data consistency..."
          
          # Check referential integrity across all entities
          psql "$SUPABASE_DB_URL" -c "
            DO \$\$
            DECLARE
                integrity_issues INTEGER := 0;
            BEGIN
                -- Check contact-organization relationships
                SELECT COUNT(*) INTO integrity_issues
                FROM contacts c 
                LEFT JOIN organizations o ON c.organization_id = o.id 
                WHERE c.organization_id IS NOT NULL AND o.id IS NULL;
                
                IF integrity_issues > 0 THEN
                    RAISE EXCEPTION 'Data integrity violation: % orphaned contacts', integrity_issues;
                END IF;
                
                -- Check opportunity relationships
                SELECT COUNT(*) INTO integrity_issues
                FROM opportunities op
                LEFT JOIN contacts c ON op.principal_id = c.id
                WHERE op.principal_id IS NOT NULL AND c.id IS NULL;
                
                IF integrity_issues > 0 THEN
                    RAISE EXCEPTION 'Data integrity violation: % orphaned opportunities', integrity_issues;
                END IF;
                
                RAISE NOTICE '✅ Data consistency validation passed';
            END
            \$\$;
          "
          
      - name: Upload Integration Test Results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: integration-test-results
          path: sql/tests/results/
          retention-days: 30

  # Phase 6: Extended Testing Categories
  extended-tests:
    name: Extended Tests (Migration, Stress, Regression, Edge, Recovery, Monitoring)
    runs-on: ubuntu-latest
    needs: [setup-and-validate, unit-tests, performance-tests]
    timeout-minutes: 35
    
    strategy:
      matrix:
        test-category: [migration, stress, regression, edge, recovery, monitoring]
      fail-fast: false
      max-parallel: 3
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_supabase_crm
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Test Environment for ${{ matrix.test-category }}
        env:
          PGPASSWORD: postgres
          SUPABASE_DB_URL: postgresql://postgres:postgres@localhost:5432/test_supabase_crm
        run: |
          # Install dependencies
          sudo apt-get update -qq
          sudo apt-get install -yqq postgresql-contrib pgtap
          sudo cpan -T TAP::Parser::SourceHandler::pgTAP
          
          # Setup database and test framework
          find sql -name "*.sql" -not -path "*/tests/*" -not -name "*test*" | sort | while read -r file; do
            psql -h localhost -U postgres -d test_supabase_crm -f "$file" >/dev/null
          done
          
          chmod +x sql/tests/run_tests.sh
          ./sql/tests/run_tests.sh --setup-only
          
      - name: Execute ${{ matrix.test-category }} Tests
        env:
          SUPABASE_DB_URL: postgresql://postgres:postgres@localhost:5432/test_supabase_crm
        run: |
          echo "🧩 Executing ${{ matrix.test-category }} tests..."
          
          # Run category-specific tests
          case "${{ matrix.test-category }}" in
            migration)
              ./sql/tests/run_tests.sh --migration --verbose
              ;;
            stress)
              ./sql/tests/run_tests.sh --stress --verbose
              ;;
            regression)
              ./sql/tests/run_tests.sh --regression --verbose
              ;;
            edge)
              ./sql/tests/run_tests.sh --edge --verbose
              ;;
            recovery)
              ./sql/tests/run_tests.sh --recovery --verbose
              ;;
            monitoring)
              ./sql/tests/run_tests.sh --monitoring --verbose
              ;;
          esac
          
          if [ $? -eq 0 ]; then
            echo "✅ ${{ matrix.test-category }} tests completed successfully"
          else
            echo "❌ ${{ matrix.test-category }} tests failed"
            exit 1
          fi
          
      - name: Upload ${{ matrix.test-category }} Test Results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: ${{ matrix.test-category }}-test-results
          path: sql/tests/results/
          retention-days: 30

  # Phase 7: Test Results Analysis and Quality Gate
  test-results-analysis:
    name: Test Results Analysis & Quality Gate
    runs-on: ubuntu-latest
    needs: [unit-tests, security-tests, performance-tests, integration-tests, extended-tests]
    if: always()
    timeout-minutes: 15
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Node.js for Analysis
        uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
          
      - name: Download All Test Results
        uses: actions/download-artifact@v3
        with:
          path: test-results/
          
      - name: Install Analysis Dependencies
        run: |
          # Install test result analysis tools
          npm install -g tap-spec tap-summary junit2html
          sudo apt-get update -qq
          sudo apt-get install -yqq jq bc
          
      - name: Analyze Test Results
        run: |
          echo "📊 Analyzing comprehensive test results..."
          
          # Create analysis directory
          mkdir -p analysis-results
          
          # Initialize counters
          total_tests=0
          passed_tests=0
          failed_tests=0
          total_categories=0
          
          # Process each test category
          for category_dir in test-results/*/; do
            if [ -d "$category_dir" ]; then
              category=$(basename "$category_dir" | sed 's/-test-results$//')
              echo "Processing category: $category"
              
              # Count tests if results file exists
              if [ -f "$category_dir/test_results.json" ]; then
                category_total=$(jq '.total_tests // 0' "$category_dir/test_results.json")
                category_passed=$(jq '.passed_tests // 0' "$category_dir/test_results.json")
                category_failed=$(jq '.failed_tests // 0' "$category_dir/test_results.json")
                
                total_tests=$((total_tests + category_total))
                passed_tests=$((passed_tests + category_passed))
                failed_tests=$((failed_tests + category_failed))
                total_categories=$((total_categories + 1))
                
                echo "  $category: $category_passed/$category_total passed"
              fi
            fi
          done
          
          # Calculate success rate
          if [ $total_tests -gt 0 ]; then
            success_rate=$(echo "scale=2; $passed_tests * 100 / $total_tests" | bc)
          else
            success_rate=0
          fi
          
          # Generate summary
          cat > analysis-results/test_summary.json << EOF
          {
            "total_tests": $total_tests,
            "passed_tests": $passed_tests,
            "failed_tests": $failed_tests,
            "success_rate": $success_rate,
            "categories_tested": $total_categories,
            "quality_gate_passed": $([ $(echo "$success_rate >= $MIN_SUCCESS_RATE" | bc) -eq 1 ] && echo "true" || echo "false"),
            "timestamp": "$(date -Iseconds)"
          }
        EOF
          
          echo "📋 Test Summary:"
          echo "  Total Tests: $total_tests"
          echo "  Passed: $passed_tests"
          echo "  Failed: $failed_tests"
          echo "  Success Rate: ${success_rate}%"
          echo "  Categories: $total_categories"
          
          # Store results for quality gate
          echo "TOTAL_TESTS=$total_tests" >> $GITHUB_ENV
          echo "PASSED_TESTS=$passed_tests" >> $GITHUB_ENV
          echo "FAILED_TESTS=$failed_tests" >> $GITHUB_ENV
          echo "SUCCESS_RATE=$success_rate" >> $GITHUB_ENV
          
      - name: Generate Comprehensive Report
        run: |
          echo "📄 Generating comprehensive test report..."
          
          # Create HTML report
          cat > analysis-results/comprehensive_report.html << 'EOF'
          <!DOCTYPE html>
          <html>
          <head>
              <title>Database Testing Framework - Comprehensive Report</title>
              <meta charset="UTF-8">
              <style>
                  body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; margin: 40px; background: #f8f9fa; }
                  .header { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 30px; border-radius: 12px; text-align: center; }
                  .summary { display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; margin: 30px 0; }
                  .metric { background: white; padding: 25px; border-radius: 12px; text-align: center; box-shadow: 0 4px 6px rgba(0,0,0,0.1); }
                  .metric h3 { margin: 0 0 15px 0; color: #495057; font-size: 16px; }
                  .metric .value { font-size: 3em; font-weight: bold; margin-bottom: 10px; }
                  .success { border-left: 5px solid #28a745; }
                  .success .value { color: #28a745; }
                  .warning { border-left: 5px solid #ffc107; }
                  .warning .value { color: #ffc107; }
                  .error { border-left: 5px solid #dc3545; }
                  .error .value { color: #dc3545; }
                  .category-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin: 20px 0; }
                  .category { background: white; padding: 20px; border-radius: 12px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
                  .status-badge { display: inline-block; padding: 4px 12px; border-radius: 20px; font-size: 14px; font-weight: bold; }
                  .status-success { background: #d4edda; color: #155724; }
                  .status-failure { background: #f8d7da; color: #721c24; }
                  .footer { margin-top: 40px; padding: 20px; background: white; border-radius: 12px; text-align: center; color: #6c757d; }
              </style>
          </head>
          <body>
              <div class="header">
                  <h1>🗄️ Database Testing Framework</h1>
                  <p>Comprehensive Test Results Report</p>
                  <p><strong>Generated:</strong> $(date)</p>
              </div>
          EOF
          
          # Add dynamic content based on test results
          cat >> analysis-results/comprehensive_report.html << EOF
              <div class="summary">
                  <div class="metric success">
                      <h3>Total Tests</h3>
                      <div class="value">$TOTAL_TESTS</div>
                  </div>
                  <div class="metric success">
                      <h3>Passed</h3>
                      <div class="value">$PASSED_TESTS</div>
                  </div>
                  <div class="metric $([ $FAILED_TESTS -eq 0 ] && echo 'success' || echo 'error')">
                      <h3>Failed</h3>
                      <div class="value">$FAILED_TESTS</div>
                  </div>
                  <div class="metric $([ $(echo "$SUCCESS_RATE >= $MIN_SUCCESS_RATE" | bc) -eq 1 ] && echo 'success' || echo 'warning')">
                      <h3>Success Rate</h3>
                      <div class="value">${SUCCESS_RATE}%</div>
                  </div>
              </div>
              
              <div class="footer">
                  <h3>🚀 Quality Gate Status</h3>
                  <p class="$([ $(echo "$SUCCESS_RATE >= $MIN_SUCCESS_RATE" | bc) -eq 1 ] && echo 'status-success' || echo 'status-failure') status-badge">
                      $([ $(echo "$SUCCESS_RATE >= $MIN_SUCCESS_RATE" | bc) -eq 1 ] && echo 'PASSED' || echo 'FAILED')
                  </p>
              </div>
          </body>
          </html>
        EOF
          
      - name: Quality Gate Assessment
        run: |
          echo "🚪 Performing quality gate assessment..."
          
          # Check success rate threshold
          if [ $(echo "$SUCCESS_RATE >= $MIN_SUCCESS_RATE" | bc) -eq 1 ]; then
            echo "✅ Quality gate PASSED: Success rate ${SUCCESS_RATE}% meets minimum ${MIN_SUCCESS_RATE}%"
            echo "QUALITY_GATE_STATUS=PASSED" >> $GITHUB_ENV
          else
            echo "❌ Quality gate FAILED: Success rate ${SUCCESS_RATE}% below minimum ${MIN_SUCCESS_RATE}%"
            echo "QUALITY_GATE_STATUS=FAILED" >> $GITHUB_ENV
          fi
          
          # Additional quality checks
          echo "🔍 Additional quality assessments:"
          
          if [ $TOTAL_TESTS -ge 800 ]; then
            echo "✅ Test coverage: $TOTAL_TESTS tests (exceeds minimum 800)"
          else
            echo "⚠️ Test coverage: $TOTAL_TESTS tests (below expected 800+)"
          fi
          
          if [ $FAILED_TESTS -eq 0 ]; then
            echo "✅ Zero test failures"
          else
            echo "⚠️ $FAILED_TESTS test failures detected"
          fi
          
      - name: Upload Comprehensive Analysis
        uses: actions/upload-artifact@v3
        with:
          name: comprehensive-test-analysis
          path: analysis-results/
          retention-days: 90
          
      - name: Comment PR with Results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            
            const summary = `## 🗄️ Database Testing Framework Results
            
            **Quality Gate Status:** ${process.env.QUALITY_GATE_STATUS === 'PASSED' ? '✅ PASSED' : '❌ FAILED'}
            
            | Metric | Value |
            |--------|-------|
            | Total Tests | ${process.env.TOTAL_TESTS} |
            | Passed | ${process.env.PASSED_TESTS} |
            | Failed | ${process.env.FAILED_TESTS} |
            | Success Rate | ${process.env.SUCCESS_RATE}% |
            
            **Test Categories Executed:**
            - Unit Tests (25+ tests)
            - Security Tests (217+ tests) 
            - Performance Tests (188+ tests)
            - Integration Tests (229+ tests)
            - Extended Tests (Migration, Stress, Regression, Edge, Recovery, Monitoring)
            
            ${process.env.QUALITY_GATE_STATUS === 'FAILED' ? 
              '⚠️ **Quality gate failed** - Review test failures before merging.' : 
              '🚀 **All systems go** - Database tests passing with high confidence.'
            }`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });
            
  # Phase 8: Production Deployment Gate
  production-deployment-gate:
    name: Production Deployment Gate
    runs-on: ubuntu-latest
    needs: test-results-analysis
    if: |
      always() && 
      github.ref == 'refs/heads/main' && 
      needs.test-results-analysis.result == 'success'
    
    steps:
      - name: Validate Production Readiness
        run: |
          echo "🏭 Validating production readiness..."
          
          # Download analysis results to check quality gate
          if [ -f "analysis-results/test_summary.json" ]; then
            quality_gate_passed=$(jq -r '.quality_gate_passed' analysis-results/test_summary.json)
            
            if [ "$quality_gate_passed" = "true" ]; then
              echo "✅ Production deployment approved"
              echo "  - All database tests passed successfully"
              echo "  - Performance requirements met"
              echo "  - Security validation completed"
              echo "  - Quality gate criteria satisfied"
            else
              echo "❌ Production deployment blocked"
              echo "  - Quality gate failed"
              echo "  - Manual review required"
              exit 1
            fi
          else
            echo "❌ Cannot validate readiness - analysis results not found"
            exit 1
          fi
          
      - name: Trigger Production Deployment
        if: success()
        uses: peter-evans/repository-dispatch@v2
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          event-type: production-deploy-approved
          client-payload: |
            {
              "test_status": "passed",
              "commit_sha": "${{ github.sha }}",
              "success_rate": "${{ env.SUCCESS_RATE }}",
              "total_tests": "${{ env.TOTAL_TESTS }}",
              "timestamp": "${{ github.run_id }}"
            }

  # Cleanup and Notification
  cleanup-and-notify:
    name: Cleanup & Notifications
    runs-on: ubuntu-latest
    needs: [test-results-analysis, production-deployment-gate]
    if: always()
    
    steps:
      - name: Send Slack Notification
        if: always() && env.SLACK_WEBHOOK_URL
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: |
            🗄️ Database Testing Framework Completed
            
            📊 Results:
            • Total Tests: ${{ env.TOTAL_TESTS }}
            • Success Rate: ${{ env.SUCCESS_RATE }}%
            • Quality Gate: ${{ env.QUALITY_GATE_STATUS }}
            
            🔗 View Details: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          
      - name: Cleanup Temporary Resources
        if: always()
        run: |
          echo "🧹 Cleaning up temporary resources..."
          # Any cleanup logic here
          echo "✅ Cleanup completed"